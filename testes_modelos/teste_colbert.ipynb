{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "3WnIaQiQ7ILp"
      },
      "outputs": [],
      "source": [
        "import docker\n",
        "from vespa.io import VespaResponse, VespaQueryResponse\n",
        "from vespa.package import (\n",
        "    ApplicationPackage,\n",
        "    Field,\n",
        "    Schema,\n",
        "    Document,\n",
        "    HNSW,\n",
        "    RankProfile,\n",
        "    Component,\n",
        "    Parameter,\n",
        "    FieldSet,\n",
        "    GlobalPhaseRanking,\n",
        "    Function,\n",
        "    FirstPhaseRanking, SecondPhaseRanking\n",
        ")\n",
        "from vespa.deployment import VespaDocker\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [],
      "source": [
        "package = ApplicationPackage(\n",
        "            name=\"testecolbert\",\n",
        "            schema=[\n",
        "                Schema(\n",
        "                    name=\"doc\",\n",
        "                    document=Document(\n",
        "                        fields=[\n",
        "                            Field(name=\"id\", type=\"string\", indexing=[\"summary\"]),\n",
        "                            Field(name=\"title\", type=\"string\", indexing=[\"index\", \"summary\"]),\n",
        "                            Field(\n",
        "                                name=\"authors\",\n",
        "                                type=\"string\",\n",
        "                                indexing=[\"index\", \"summary\"],\n",
        "                                bolding=False,\n",
        "                            ),\n",
        "                            Field(\n",
        "                                name=\"categories\",\n",
        "                                type=\"string\",\n",
        "                                indexing=[\"index\", \"summary\"],\n",
        "                                bolding=False,\n",
        "                            ),\n",
        "                            Field(name=\"description\", type=\"array<string>\", indexing=[\"summary\", \"index\"]),\n",
        "                            Field(\n",
        "                                name=\"embedding\",\n",
        "                                type=\"tensor<bfloat16>(steps{}, x[384])\",\n",
        "                                indexing=[\n",
        "                                    \"input description\",\n",
        "                                    'for_each { (input title || \"\") . \" \" . ( _ || \"\") }',\n",
        "                                    \"embed e5\",\n",
        "                                    \"attribute\",\n",
        "                                ],\n",
        "                                attribute=[\"distance-metric: angular\"],\n",
        "                                is_document_field=False,\n",
        "                            ),\n",
        "                            Field(\n",
        "                                name=\"colbert\",\n",
        "                                type=\"tensor<int8>(description{}, token{}, v[16])\",\n",
        "                                indexing=[\"input description\", \"embed colbert description\", \"attribute\"],\n",
        "                                is_document_field=False,\n",
        "                            ),\n",
        "                        ]\n",
        "                    ),            \n",
        "                    fieldsets=[FieldSet(name=\"default\", fields=[\"title\", \"authors\", \"description\", \"categories\"])],\n",
        "                    rank_profiles=[\n",
        "                        RankProfile(\n",
        "                            name=\"bm25\",\n",
        "                            inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
        "                            functions=[\n",
        "                                Function(name=\"bm25sum\", expression=\"bm25(description) + bm25(categories)\")\n",
        "                            ],\n",
        "                            first_phase=\"bm25sum\",\n",
        "                        ),\n",
        "                        RankProfile(\n",
        "                            name=\"semantic\",\n",
        "                            inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
        "                            first_phase=\"closeness(field, embedding)\",\n",
        "                        ),\n",
        "                        RankProfile(\n",
        "                            name=\"fusion\",\n",
        "                            inherits=\"bm25\",\n",
        "                            inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
        "                            first_phase=\"closeness(field, embedding)\",\n",
        "                            global_phase=GlobalPhaseRanking(\n",
        "                                expression=\"reciprocal_rank_fusion(bm25sum, closeness(field, embedding))\",\n",
        "                                rerank_count=1000,\n",
        "                            ),\n",
        "                        ),\n",
        "                        RankProfile(\n",
        "                            name=\"twofase\",\n",
        "                            inputs=[(\"query(q)\", \"tensor<float>(x[384])\")],\n",
        "                            functions=[\n",
        "                                Function(name=\"bm25sum\", expression=\"bm25(description) + bm25(categories)\"),\n",
        "                                Function(name=\"closeness\", expression=\"closeness(field, embedding)\"),\n",
        "                            ],\n",
        "                            first_phase=FirstPhaseRanking(expression = \"bm25sum\"),\n",
        "                            second_phase=SecondPhaseRanking(expression = \"closeness\", rerank_count=1000),\n",
        "                            match_features=[\"bm25sum\", \"closeness\"],\n",
        "                        ),\n",
        "                        RankProfile(\n",
        "                            name=\"colbert_local\",\n",
        "                            inputs=[\n",
        "                                (\"query(q)\", \"tensor<float>(x[384])\"),\n",
        "                                (\"query(qt)\", \"tensor<float>(querytoken{}, v[128])\"),\n",
        "                            ],\n",
        "                            functions=[\n",
        "                                Function(name=\"cos_sim\", expression=\"closeness(field, embedding)\"),\n",
        "                                Function(\n",
        "                                    name=\"max_sim_per_steps\",\n",
        "                                    expression=\"\"\"\n",
        "                                        sum(\n",
        "                                            reduce(\n",
        "                                                sum(\n",
        "                                                    query(qt) * unpack_bits(attribute(colbert)) , v\n",
        "                                                ),\n",
        "                                                max, token\n",
        "                                            ),\n",
        "                                            querytoken\n",
        "                                        )\n",
        "                                    \"\"\",\n",
        "                                ),\n",
        "                                Function(\n",
        "                                    name=\"max_sim_local\", expression=\"reduce(max_sim_per_steps, max, description)\"\n",
        "                                ),\n",
        "                            ],\n",
        "                            first_phase=FirstPhaseRanking(expression=\"cos_sim\"),\n",
        "                            second_phase=SecondPhaseRanking(expression=\"max_sim_local\"),\n",
        "                            match_features=[\"cos_sim\", \"max_sim_local\", \"max_sim_per_steps\"],\n",
        "                        ),\n",
        "                        RankProfile(\n",
        "                            name=\"colbert_global\",\n",
        "                            inputs=[\n",
        "                                (\"query(q)\", \"tensor<float>(x[384])\"),\n",
        "                                (\"query(qt)\", \"tensor<float>(querytoken{}, v[128])\"),\n",
        "                            ],\n",
        "                            functions=[\n",
        "                                Function(name=\"cos_sim\", expression=\"closeness(field, embedding)\"),\n",
        "                                Function(\n",
        "                                    name=\"max_sim_cross_steps\",\n",
        "                                    expression=\"\"\"\n",
        "                                        sum(\n",
        "                                            reduce(\n",
        "                                                sum(\n",
        "                                                    query(qt) *  unpack_bits(attribute(colbert)) , v\n",
        "                                                ),\n",
        "                                                max, token, description\n",
        "                                            ),\n",
        "                                            querytoken\n",
        "                                        )\n",
        "                                        \"\"\"\n",
        "                                ),\n",
        "                                Function(\n",
        "                                    name=\"max_sim_global\", expression=\"reduce(max_sim_cross_steps, max)\"\n",
        "                                ),\n",
        "                            ],\n",
        "                            first_phase=FirstPhaseRanking(expression=\"cos_sim\"),\n",
        "                            second_phase=SecondPhaseRanking(expression=\"max_sim_global\", rerank_count=5),\n",
        "                            match_features=[\n",
        "                            \"cos_sim\",\n",
        "                            \"max_sim_global\",\n",
        "                            \"max_sim_cross_steps\",\n",
        "                            ],\n",
        "                        )\n",
        "                    ]\n",
        "                )\n",
        "            ],\n",
        "            components=[\n",
        "                Component(\n",
        "                    id=\"e5\",\n",
        "                    type=\"hugging-face-embedder\",\n",
        "                    parameters=[\n",
        "                        Parameter(\n",
        "                            name=\"transformer-model\",\n",
        "                            args={\n",
        "                                \"url\": \"https://huggingface.co/intfloat/e5-small-v2/resolve/main/model.onnx\"\n",
        "                            },\n",
        "                        ),\n",
        "                        Parameter(\n",
        "                            name=\"tokenizer-model\",\n",
        "                            args={\n",
        "                                \"url\": \"https://huggingface.co/intfloat/e5-small-v2/raw/main/tokenizer.json\"\n",
        "                            },\n",
        "                        ),\n",
        "                    ],\n",
        "                ),\n",
        "                Component(\n",
        "                    id=\"colbert\",\n",
        "                    type=\"colbert-embedder\",\n",
        "                    parameters=[\n",
        "                        Parameter(\n",
        "                            name=\"transformer-model\",\n",
        "                            args={\n",
        "                                \"url\": \"https://huggingface.co/colbert-ir/colbertv2.0/resolve/main/model.onnx\"\n",
        "                            },\n",
        "                        ),\n",
        "                        Parameter(\n",
        "                            name=\"tokenizer-model\",\n",
        "                            args={\n",
        "                                \"url\": \"https://huggingface.co/colbert-ir/colbertv2.0/raw/main/tokenizer.json\"\n",
        "                            },\n",
        "                        ),\n",
        "                    ],\n",
        "                ),\n",
        "            ]\n",
        "        )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "Qfk-eFnD9T_L"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Waiting for configuration server, 0/60 seconds...\n",
            "Waiting for configuration server, 5/60 seconds...\n",
            "Waiting for configuration server, 10/60 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 0/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 5/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 10/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 15/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 20/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 25/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 30/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 35/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 40/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 45/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 50/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 55/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 60/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 65/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 70/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 75/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 80/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 85/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 90/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 95/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 100/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 105/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Waiting for application status, 110/300 seconds...\n",
            "Using plain http against endpoint http://localhost:8080/ApplicationStatus\n",
            "Application is up!\n",
            "Finished deployment.\n"
          ]
        }
      ],
      "source": [
        "vespa_docker = VespaDocker()\n",
        "app = vespa_docker.deploy(application_package=package)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [],
      "source": [
        "def transform_row(row):\n",
        "    return {\n",
        "        \"id\": row[\"id\"],\n",
        "        \"fields\": {\"title\": row[\"title\"], \"authors\": row[\"authors\"], \"description\": row[\"description\"], \"categories\": row[\"categories\"], \"id\": row[\"id\"]},\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [],
      "source": [
        "def callback(response:VespaResponse, id:str):\n",
        "    if not response.is_successful():\n",
        "        print(f\"Error when feeding document {id}: {response.get_json()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Itffv9qI9UtA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"https://raw.githubusercontent.com/bernardovma/dados_livros/main/data.csv\")\n",
        "df['id'] = range(1, len(df) + 1)\n",
        "df = df.fillna(\"\")\n",
        "df['description'] = df['description'].apply(lambda x: [x])\n",
        "vespa_feed = df.apply(transform_row, axis=1).tolist()\n",
        "\n",
        "app.feed_iterable(vespa_feed, schema=\"doc\", namespace=\"bookrec\", callback=callback)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hits_as_df(response, fields):\n",
        "    records = []\n",
        "    for hit in response.hits:\n",
        "        record = {}\n",
        "        for field in fields:\n",
        "            record[field] = hit['fields'].get(field, None) \n",
        "        records.append(record)\n",
        "    return pd.DataFrame(records)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "70lRzqba9X1Y"
      },
      "outputs": [],
      "source": [
        "def query_colbert(input_query):\n",
        "    with app.syncio(connections=25) as session:\n",
        "        query = input_query\n",
        "        response: VespaQueryResponse = session.query(\n",
        "            yql=\"select * from sources * where userQuery() or ({targetHits:1000}nearestNeighbor(embedding,q)) limit 10\",\n",
        "            query=query,\n",
        "            ranking=\"colbert_local\",\n",
        "            body={\n",
        "                \"input.query(q)\": f'embed(e5, \"{query}\")',\n",
        "                \"input.query(qt)\": f'embed(colbert, \"{query}\")'\n",
        "            },\n",
        "        )\n",
        "        assert response.is_successful()\n",
        "\n",
        "    return hits_as_df(response, ['id', 'title', 'authors', 'description', 'categories'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "YIEMC8g19ecH"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>authors</th>\n",
              "      <th>description</th>\n",
              "      <th>categories</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3263</td>\n",
              "      <td>Two Complete Novels</td>\n",
              "      <td>Douglas Adams</td>\n",
              "      <td>[Following themes of zany space exploration, t...</td>\n",
              "      <td>Detective and mystery stories, English.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6459</td>\n",
              "      <td>The Algebraist</td>\n",
              "      <td>Iain M. Banks</td>\n",
              "      <td>[It is 4034 AD. Humanity has made it to the st...</td>\n",
              "      <td>Fiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>878</td>\n",
              "      <td>The Fabric of the Cosmos</td>\n",
              "      <td>Brian Greene</td>\n",
              "      <td>[From the bestselling author of The Elegant Un...</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3254</td>\n",
              "      <td>The Complete Science Fiction Treasury of H.G. ...</td>\n",
              "      <td>H. G. Wells</td>\n",
              "      <td>[Includes fantasies of travel in time and spac...</td>\n",
              "      <td>Science fiction, English.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5628</td>\n",
              "      <td>A Short History of Nearly Everything</td>\n",
              "      <td>Bill Bryson</td>\n",
              "      <td>[In this book Bill Bryson explores the most in...</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>1180</td>\n",
              "      <td>Gulliver's Travels</td>\n",
              "      <td>Jonathan Swift;Claude Rawson;Ian Higgins</td>\n",
              "      <td>[\"Gulliver's travels purports to be a travel b...</td>\n",
              "      <td>Fiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3142</td>\n",
              "      <td>Bad Astronomy</td>\n",
              "      <td>Philip C. Plait</td>\n",
              "      <td>[Advance praise for Philip Plait s Bad Astrono...</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3688</td>\n",
              "      <td>A Brief History of Time</td>\n",
              "      <td>Stephen Hawking</td>\n",
              "      <td>[Stephen Hawking's A Brief History of Time has...</td>\n",
              "      <td>Cosmology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>5619</td>\n",
              "      <td>Pyramids of Montauk</td>\n",
              "      <td>Preston B. Nichols;Peter Moon</td>\n",
              "      <td>[During WWII there was an attempt to achieve i...</td>\n",
              "      <td>Fiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3470</td>\n",
              "      <td>A Brief History of Time</td>\n",
              "      <td>Stephen Hawking</td>\n",
              "      <td>[An anniversary edition of a now-classic surve...</td>\n",
              "      <td>Science</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     id                                              title  \\\n",
              "0  3263                                Two Complete Novels   \n",
              "1  6459                                     The Algebraist   \n",
              "2   878                           The Fabric of the Cosmos   \n",
              "3  3254  The Complete Science Fiction Treasury of H.G. ...   \n",
              "4  5628               A Short History of Nearly Everything   \n",
              "5  1180                                 Gulliver's Travels   \n",
              "6  3142                                      Bad Astronomy   \n",
              "7  3688                            A Brief History of Time   \n",
              "8  5619                                Pyramids of Montauk   \n",
              "9  3470                            A Brief History of Time   \n",
              "\n",
              "                                    authors  \\\n",
              "0                             Douglas Adams   \n",
              "1                             Iain M. Banks   \n",
              "2                              Brian Greene   \n",
              "3                               H. G. Wells   \n",
              "4                               Bill Bryson   \n",
              "5  Jonathan Swift;Claude Rawson;Ian Higgins   \n",
              "6                           Philip C. Plait   \n",
              "7                           Stephen Hawking   \n",
              "8             Preston B. Nichols;Peter Moon   \n",
              "9                           Stephen Hawking   \n",
              "\n",
              "                                         description  \\\n",
              "0  [Following themes of zany space exploration, t...   \n",
              "1  [It is 4034 AD. Humanity has made it to the st...   \n",
              "2  [From the bestselling author of The Elegant Un...   \n",
              "3  [Includes fantasies of travel in time and spac...   \n",
              "4  [In this book Bill Bryson explores the most in...   \n",
              "5  [\"Gulliver's travels purports to be a travel b...   \n",
              "6  [Advance praise for Philip Plait s Bad Astrono...   \n",
              "7  [Stephen Hawking's A Brief History of Time has...   \n",
              "8  [During WWII there was an attempt to achieve i...   \n",
              "9  [An anniversary edition of a now-classic surve...   \n",
              "\n",
              "                                categories  \n",
              "0  Detective and mystery stories, English.  \n",
              "1                                  Fiction  \n",
              "2                                  Science  \n",
              "3                Science fiction, English.  \n",
              "4                                  Science  \n",
              "5                                  Fiction  \n",
              "6                                  Science  \n",
              "7                                Cosmology  \n",
              "8                                  Fiction  \n",
              "9                                  Science  "
            ]
          },
          "execution_count": 73,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "query_colbert('books about space travel')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_generic_questions_twofase(book_description, book_category):\n",
        "    prompt = f\"Generate three generic questions about a book, given the following description: '{book_description} ans its category (it can be multiple categories, and in some cases the are no categories shown): '{book_category}'. The questions should be broad and not specific, not giving away the book title, being more general and applicable to other books, but at the same time giving elements to discuss the book.\"\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "    response = openai.chat.completions.create(\n",
        "        model=\"gpt-3.5-turbo\",\n",
        "        messages=messages,\n",
        "        max_tokens=150,\n",
        "        temperature=0.7,\n",
        "    )\n",
        "    questions = response.choices[0].message.content.strip().split(\"\\n\")\n",
        "    return [q for q in questions if q]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "teste_df = df.sample(n=100)\n",
        "teste_df = teste_df[['title', 'description', 'categories']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [],
      "source": [
        "#openai.api_key = openai api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [],
      "source": [
        "def dcg(relevance_scores, p):\n",
        "    relevance_scores = np.asfarray(relevance_scores)[:p]\n",
        "    if relevance_scores.size:\n",
        "        return np.sum(relevance_scores / np.log2(np.arange(2, relevance_scores.size + 2)))\n",
        "    return 0.0\n",
        "\n",
        "def ndcg(relevance_scores, p):\n",
        "    dcg_p = dcg(relevance_scores, p)\n",
        "    idcg_p = dcg(sorted(relevance_scores, reverse=True), p)\n",
        "    if idcg_p == 0:\n",
        "        return 0.0\n",
        "    return dcg_p / idcg_p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_colbert_local = {}\n",
        "total_appearance_count_colbert_local = 0\n",
        "total_questions_colbert_local = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing book: Guardians of Ga'hoole\n",
            "Processing book: Starshield Sentinels\n",
            "Processing book: The Lord God Made Them All\n",
            "Processing book: NYC Ballet Workout\n",
            "Processing book: Under The Influence\n",
            "Processing book: A Farewell to Arms\n",
            "Processing book: Jitterbug Perfume\n",
            "Processing book: The Deep End of the Ocean\n",
            "Processing book: From Far Away\n",
            "Processing book: Shadow Game\n",
            "Processing book: Garden State\n",
            "Processing book: River of Shadows\n",
            "Processing book: Bad Astronomy\n",
            "Processing book: The Science Book\n",
            "Processing book: The World, the Text, and the Critic\n",
            "Processing book: Last Wish\n",
            "Processing book: The Classic Treasury of Hans Christian Andersen\n",
            "Processing book: Kiss\n",
            "Processing book: The Picture of Dorian Gray\n",
            "Processing book: Magic Bites\n",
            "Processing book: The Problem of Pain\n",
            "Processing book: On Becoming a Novelist\n",
            "Processing book: Autobiography of Thomas Jefferson\n",
            "Processing book: The Unadulterated Cat\n",
            "Processing book: The White Man's Burden\n",
            "Processing book: Fell\n",
            "Processing book: Good Omens\n",
            "Processing book: Glass Soup\n",
            "Processing book: The Boomer Bible\n",
            "Processing book: The Missing Piece Meets the Big O\n",
            "Processing book: Night Shift\n",
            "Processing book: The Ravishing of Lol Stein\n",
            "Processing book: A Fairly Honourable Defeat\n",
            "Processing book: High Five\n",
            "Processing book: Cuba\n",
            "Processing book: Them\n",
            "Processing book: Killobyte\n",
            "Processing book: Everest\n",
            "Processing book: Where We Are, what We See\n",
            "Processing book: The Guide to Dan Brown's The Solomon Key\n",
            "Processing book: Youth in Revolt\n",
            "Processing book: An Inconvenient Truth\n",
            "Processing book: Fight Club: A Novel\n",
            "Processing book: C.G. Jung and Hermann Hesse\n",
            "Processing book: The Rough Guide to Vietnam\n",
            "Processing book: Mysteria\n",
            "Processing book: In the Realm of Elizabeth\n",
            "Processing book: Flowers for Algernon\n",
            "Processing book: The Satanic Verses\n",
            "Processing book: The Favored Child\n",
            "Processing book: The Essential Calvin And Hobbes\n",
            "Processing book: The Cross from a Distance\n",
            "Processing book: Debt of Bones\n",
            "Processing book: Dancing on Air\n",
            "Processing book: Baby Einstein: Babies\n",
            "Processing book: Werewolves Don't Go to Summer Camp\n",
            "Processing book: Reptiles and Amphibians\n",
            "Processing book: Titan\n",
            "Processing book: Little Miss Birthday\n",
            "Processing book: The Annotated Lolita\n",
            "Processing book: A Birthday for Frances\n",
            "Processing book: Underworld\n",
            "Processing book: The Dance of the Dissident Daughter\n",
            "Processing book: Prisoner's Dilemma\n",
            "Processing book: Messenger\n",
            "Processing book: Palm Sunday\n",
            "Processing book: The Smoke Thief\n",
            "Processing book: Non-Fiction\n",
            "Processing book: The Mistress's Daughter\n",
            "Processing book: The Spectator Bird\n",
            "Processing book: Medea\n",
            "Processing book: War and Peace\n",
            "Processing book: The Ring Finger Falls Silent\n",
            "Processing book: Eating for Life\n",
            "Processing book: Same Sex in the City\n",
            "Processing book: Hitty Her First Hundred Years\n",
            "Processing book: Fargo Rock City\n",
            "Processing book: The Years\n",
            "Processing book: The Shining\n",
            "Processing book: The Red Notebook\n",
            "Processing book: Night Lives\n",
            "Processing book: The Feeling Good Handbook\n",
            "Processing book: First Comes Love\n",
            "Processing book: The Botany of Desire\n",
            "Processing book: The Pilgrimage\n",
            "Processing book: A Writer's Diary\n",
            "Processing book: Antitrust Law, Second Edition\n",
            "Processing book: The Chomsky Reader\n",
            "Processing book: The Oedipus Plays of Sophocles\n",
            "Processing book: The Blue and Brown Books\n",
            "Processing book: Oliver Twist\n",
            "Processing book: Sammlung\n",
            "Processing book: The Greatest Sailing Stories Ever Told\n",
            "Processing book: A Murder is Announced\n",
            "Processing book: What is Art?\n",
            "Processing book: Haussmann, Or the Distinction\n",
            "Processing book: Betcha Can't Read Just One\n",
            "Processing book: Night Shift\n",
            "Processing book: The No. 1 Ladies' Detective Agency\n",
            "Processing book: Much Ado about Nothing\n"
          ]
        }
      ],
      "source": [
        "if results_colbert_local:\n",
        "    last_title = list(results_colbert_local.keys())[-1]\n",
        "    last_book_data = results_colbert_local.pop(last_title)\n",
        "    total_appearance_count_colbert_local -= last_book_data[\"appearance_count\"]\n",
        "    total_questions_colbert_local -= last_book_data[\"total_questions\"]\n",
        "\n",
        "start_index = len(results_colbert_local)\n",
        "books_to_process = teste_df.iloc[start_index:]\n",
        "\n",
        "for index, row in books_to_process.iterrows():\n",
        "    title = row['title']\n",
        "    print(f\"Processing book: {title}\")\n",
        "    description = row['description']\n",
        "    categories = row['categories']\n",
        "    questions = generate_generic_questions_twofase(description, categories)\n",
        "    \n",
        "    results_colbert_local[title] = {\n",
        "        \"questions\": questions,\n",
        "        \"appearance_count\": 0,\n",
        "        \"total_questions\": len(questions),\n",
        "        \"relevance_scores\": []\n",
        "    }\n",
        "    \n",
        "    for question in questions:\n",
        "        \n",
        "        search_results_colbert = query_colbert(question)\n",
        "        search_results_titles_colbert = list(search_results_colbert['title'])\n",
        "        \n",
        "        book_appears_colbert = title in search_results_titles_colbert\n",
        "        results_colbert_local[title][\"relevance_scores\"].append(int(book_appears_colbert))\n",
        "        if book_appears_colbert:\n",
        "            results_colbert_local[title][\"appearance_count\"] += 1\n",
        "    \n",
        "    total_appearance_count_colbert_local += results_colbert_local[title][\"appearance_count\"]\n",
        "    total_questions_colbert_local += results_colbert_local[title][\"total_questions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall percentage: 48.44%\n"
          ]
        }
      ],
      "source": [
        "if total_questions_colbert_local > 0:\n",
        "    overall_percentage_colbert = (total_appearance_count_colbert_local / total_questions_colbert_local) * 100\n",
        "else:\n",
        "    overall_percentage_colbert = 0\n",
        "\n",
        "print(f\"Overall percentage: {overall_percentage_colbert:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean NDCG@10 across all books: 0.6417\n"
          ]
        }
      ],
      "source": [
        "ndcg_scores_colbert = {}\n",
        "p = 10  \n",
        "for title, data in results_colbert_local.items():\n",
        "    relevance_scores = data[\"relevance_scores\"]\n",
        "    ndcg_scores_colbert[title] = ndcg(relevance_scores, p)\n",
        "\n",
        "mean_ndcg_colbert = np.mean(list(ndcg_scores_colbert.values()))\n",
        "print(f\"Mean NDCG@{p} across all books: {mean_ndcg_colbert:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "def query_colbert_global(input_query):\n",
        "    with app.syncio(connections=25) as session:\n",
        "        query = input_query\n",
        "        response: VespaQueryResponse = session.query(\n",
        "            yql=\"select * from sources * where userQuery() or ({targetHits:1000}nearestNeighbor(embedding,q)) limit 10\",\n",
        "            query=query,\n",
        "            ranking=\"colbert_global\",\n",
        "            body={\n",
        "                \"input.query(q)\": f'embed(e5, \"{query}\")',\n",
        "                \"input.query(qt)\": f'embed(colbert, \"{query}\")'\n",
        "            },\n",
        "        )\n",
        "        assert response.is_successful()\n",
        "\n",
        "    return hits_as_df(response, ['id', 'title', 'authors', 'description', 'categories'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {},
      "outputs": [],
      "source": [
        "results_colbert_local = {}\n",
        "total_appearance_count_colbert_local = 0\n",
        "total_questions_colbert_local = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing book: Guardians of Ga'hoole\n",
            "Processing book: Starshield Sentinels\n",
            "Processing book: The Lord God Made Them All\n",
            "Processing book: NYC Ballet Workout\n",
            "Processing book: Under The Influence\n",
            "Processing book: A Farewell to Arms\n",
            "Processing book: Jitterbug Perfume\n",
            "Processing book: The Deep End of the Ocean\n",
            "Processing book: From Far Away\n",
            "Processing book: Shadow Game\n",
            "Processing book: Garden State\n",
            "Processing book: River of Shadows\n",
            "Processing book: Bad Astronomy\n",
            "Processing book: The Science Book\n",
            "Processing book: The World, the Text, and the Critic\n",
            "Processing book: Last Wish\n",
            "Processing book: The Classic Treasury of Hans Christian Andersen\n",
            "Processing book: Kiss\n",
            "Processing book: The Picture of Dorian Gray\n",
            "Processing book: Magic Bites\n",
            "Processing book: The Problem of Pain\n",
            "Processing book: On Becoming a Novelist\n",
            "Processing book: Autobiography of Thomas Jefferson\n",
            "Processing book: The Unadulterated Cat\n",
            "Processing book: The White Man's Burden\n",
            "Processing book: Fell\n",
            "Processing book: Good Omens\n",
            "Processing book: Glass Soup\n",
            "Processing book: The Boomer Bible\n",
            "Processing book: The Missing Piece Meets the Big O\n",
            "Processing book: Night Shift\n",
            "Processing book: The Ravishing of Lol Stein\n",
            "Processing book: A Fairly Honourable Defeat\n",
            "Processing book: High Five\n",
            "Processing book: Cuba\n",
            "Processing book: Them\n",
            "Processing book: Killobyte\n",
            "Processing book: Everest\n",
            "Processing book: Where We Are, what We See\n",
            "Processing book: The Guide to Dan Brown's The Solomon Key\n",
            "Processing book: Youth in Revolt\n",
            "Processing book: An Inconvenient Truth\n",
            "Processing book: Fight Club: A Novel\n",
            "Processing book: C.G. Jung and Hermann Hesse\n",
            "Processing book: The Rough Guide to Vietnam\n",
            "Processing book: Mysteria\n",
            "Processing book: In the Realm of Elizabeth\n",
            "Processing book: Flowers for Algernon\n",
            "Processing book: The Satanic Verses\n",
            "Processing book: The Favored Child\n",
            "Processing book: The Essential Calvin And Hobbes\n",
            "Processing book: The Cross from a Distance\n",
            "Processing book: Debt of Bones\n",
            "Processing book: Dancing on Air\n",
            "Processing book: Baby Einstein: Babies\n",
            "Processing book: Werewolves Don't Go to Summer Camp\n",
            "Processing book: Reptiles and Amphibians\n",
            "Processing book: Titan\n",
            "Processing book: Little Miss Birthday\n",
            "Processing book: The Annotated Lolita\n",
            "Processing book: A Birthday for Frances\n",
            "Processing book: Underworld\n",
            "Processing book: The Dance of the Dissident Daughter\n",
            "Processing book: Prisoner's Dilemma\n",
            "Processing book: Messenger\n",
            "Processing book: Palm Sunday\n",
            "Processing book: The Smoke Thief\n",
            "Processing book: Non-Fiction\n",
            "Processing book: The Mistress's Daughter\n",
            "Processing book: The Spectator Bird\n",
            "Processing book: Medea\n",
            "Processing book: War and Peace\n",
            "Processing book: The Ring Finger Falls Silent\n",
            "Processing book: Eating for Life\n",
            "Processing book: Same Sex in the City\n",
            "Processing book: Hitty Her First Hundred Years\n",
            "Processing book: Fargo Rock City\n",
            "Processing book: The Years\n",
            "Processing book: The Shining\n",
            "Processing book: The Red Notebook\n",
            "Processing book: Night Lives\n",
            "Processing book: The Feeling Good Handbook\n",
            "Processing book: First Comes Love\n",
            "Processing book: The Botany of Desire\n",
            "Processing book: The Pilgrimage\n",
            "Processing book: A Writer's Diary\n",
            "Processing book: Antitrust Law, Second Edition\n",
            "Processing book: The Chomsky Reader\n",
            "Processing book: The Oedipus Plays of Sophocles\n",
            "Processing book: The Blue and Brown Books\n",
            "Processing book: Oliver Twist\n",
            "Processing book: Sammlung\n",
            "Processing book: The Greatest Sailing Stories Ever Told\n",
            "Processing book: A Murder is Announced\n",
            "Processing book: What is Art?\n",
            "Processing book: Haussmann, Or the Distinction\n",
            "Processing book: Betcha Can't Read Just One\n",
            "Processing book: Night Shift\n",
            "Processing book: The No. 1 Ladies' Detective Agency\n",
            "Processing book: Much Ado about Nothing\n"
          ]
        }
      ],
      "source": [
        "if results_colbert_local:\n",
        "    last_title = list(results_colbert_local.keys())[-1]\n",
        "    last_book_data = results_colbert_local.pop(last_title)\n",
        "    total_appearance_count_colbert_local -= last_book_data[\"appearance_count\"]\n",
        "    total_questions_colbert_local -= last_book_data[\"total_questions\"]\n",
        "\n",
        "start_index = len(results_colbert_local)\n",
        "books_to_process = teste_df.iloc[start_index:]\n",
        "\n",
        "for index, row in books_to_process.iterrows():\n",
        "    title = row['title']\n",
        "    print(f\"Processing book: {title}\")\n",
        "    description = row['description']\n",
        "    categories = row['categories']\n",
        "    questions = generate_generic_questions_twofase(description, categories)\n",
        "    \n",
        "    results_colbert_local[title] = {\n",
        "        \"questions\": questions,\n",
        "        \"appearance_count\": 0,\n",
        "        \"total_questions\": len(questions),\n",
        "        \"relevance_scores\": []\n",
        "    }\n",
        "    \n",
        "    for question in questions:\n",
        "        \n",
        "        search_results_colbert = query_colbert_global(question)\n",
        "        search_results_titles_colbert = list(search_results_colbert['title'])\n",
        "        \n",
        "        book_appears_colbert = title in search_results_titles_colbert\n",
        "        results_colbert_local[title][\"relevance_scores\"].append(int(book_appears_colbert))\n",
        "        if book_appears_colbert:\n",
        "            results_colbert_local[title][\"appearance_count\"] += 1\n",
        "    \n",
        "    total_appearance_count_colbert_local += results_colbert_local[title][\"appearance_count\"]\n",
        "    total_questions_colbert_local += results_colbert_local[title][\"total_questions\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overall percentage: 43.67%\n"
          ]
        }
      ],
      "source": [
        "if total_questions_colbert_local > 0:\n",
        "    overall_percentage_colbert = (total_appearance_count_colbert_local / total_questions_colbert_local) * 100\n",
        "else:\n",
        "    overall_percentage_colbert = 0\n",
        "\n",
        "print(f\"Overall percentage: {overall_percentage_colbert:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean NDCG@10 across all books: 0.5757\n"
          ]
        }
      ],
      "source": [
        "ndcg_scores_colbert = {}\n",
        "p = 10  \n",
        "for title, data in results_colbert_local.items():\n",
        "    relevance_scores = data[\"relevance_scores\"]\n",
        "    ndcg_scores_colbert[title] = ndcg(relevance_scores, p)\n",
        "\n",
        "mean_ndcg_colbert = np.mean(list(ndcg_scores_colbert.values()))\n",
        "print(f\"Mean NDCG@{p} across all books: {mean_ndcg_colbert:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
